
## Kafka Extended API
- Kafka Connect
- Kafka Streams
- Kafka Schema Registry



### Kafka Schema Registry
- 카프카는 bytes로 input을 받고 bytes로 publish함(바이너리 데이터만 왔다갔다함)
- 그래서 카프카는 data에 대한 검증을 하지 않는다(못한다) -> data format에 대한 정보가 없음
- 그래서 데이터 포맷에 대한 정의(Schema)를 우리가 해야 하고, 이를 등록하는 곳이 Schema Registry 이다.
- Schema Registry는 Consumer에서 올바른 데이터를 받도록 bad data를 걸러내기 위해서 사용한다~
- As-Is
![image](https://user-images.githubusercontent.com/15210906/119505861-57324600-bda8-11eb-85e7-e1a0069dc4bc.png)

- To-Be
![image](https://user-images.githubusercontent.com/15210906/119505885-5d282700-bda8-11eb-9cce-3df87393f4f5.png)

- 단점
  - 설치하는데 오래 걸린다.
  - Producer, Consumer 코드를 일부 수정해야함.
  - 러닝커브가 있다.

- Avro schema Example
![image](https://user-images.githubusercontent.com/15210906/119506784-35858e80-bda9-11eb-8198-50016d954236.png)

